{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('tcc_puc': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "77642b1de94b3ecd25ac7cee94ae6d4cd14a15f998248e7a28e862a045f813e3"
   }
  },
  "interpreter": {
   "hash": "77642b1de94b3ecd25ac7cee94ae6d4cd14a15f998248e7a28e862a045f813e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### This notebook should create a csv with the Elon Musk Tweets, containg btc releated info, sentimental analisys scores and the btc prices indexed by date"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/prbpedro/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "base_path_to_csv = os.path.join(os.getcwd() + '/eltweets/*.csv')\n",
    "csv_list = glob.glob(base_path_to_csv)\n",
    "\n",
    "df_list = [pd.read_csv(csv, index_col='id') for csv in csv_list]\n",
    "df = pd.concat(df_list)\n",
    "df = df.reset_index().drop_duplicates(subset='id', keep='first').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing tweets to sentimental analisys\n",
    "\n",
    "df['full_text'] = df['full_text'].astype('unicode')\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: ', ' ', x)\n",
    "remove_users_ref = lambda x: re.sub(\"@[A-Za-z0-9]+\",\"\",x)\n",
    "remove_links = lambda x: re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", x)\n",
    "remove_hashtags_underlines = lambda x: x.replace(\"#\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "df['full_text'] = df['full_text'].map(remove_rt).map(remove_users_ref).map(remove_links).map(remove_hashtags_underlines)\n",
    "df['full_text'] = df['full_text'].str.lower()\n",
    "df = df[df['full_text'].str.contains(\"bitcoin|btc|etherum|eth | eth|crypto|doge\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['full_text'].str.replace('&amp;', 'and')\n",
    "df['full_text'] = df['full_text'].str.replace('&', 'and')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸ’”', 'broke my heart')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸ¤£', 'laughing ')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸŽ¶', '')\n",
    "df['full_text'] = df['full_text'].str.replace(\"itâ€™s\", 'it is')\n",
    "df['full_text'] = df['full_text'].str.replace(\"donâ€™t\", 'do not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"canâ€™t\", 'can not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"wonâ€™t\", 'will not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"peopleâ€™s\", 'people')\n",
    "df['full_text'] = df['full_text'].str.replace(\"peopleâ€™s\", 'people')\n",
    "df['full_text'] = df['full_text'].str.replace(\"thereâ€™s\", 'there is')\n",
    " \n",
    "remove_pontuacao = lambda x:  re.sub(r'[^\\w\\s]', '', x)\n",
    "remove_quebra_linha = lambda x:  re.sub(r'\\\\n', ' ', x)\n",
    "remove_tabulacao = lambda x:  re.sub(r'\\\\t', ' ', x)\n",
    "remove_multiplos_espacos = lambda x:  re.sub(' +', ' ', x)\n",
    "df['full_text'] = df['full_text'].map(remove_pontuacao).map(remove_quebra_linha).map(remove_tabulacao).map(remove_multiplos_espacos)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['full_text'] = df['full_text'].astype('unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing created_at column \n",
    "# Creating influence_end_at column containing the date time that indicates the end of the influence of the tweet in the btc price\n",
    "\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['created_at'] = df['created_at'].dt.normalize()\n",
    "df['influence_end_at'] = df['created_at']  + pd.DateOffset(days=1)\n",
    "df['influence_end_at'] = df['influence_end_at'].dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating full_text_score column with the compound value of the sentimental analisys of each tweet\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "score_full_text = lambda x: analyzer.polarity_scores(x)['compound']\n",
    "score_neg_full_text = lambda x: analyzer.polarity_scores(x)['neg']\n",
    "score_neu_full_text = lambda x: analyzer.polarity_scores(x)['neu']\n",
    "score_pos_full_text = lambda x: analyzer.polarity_scores(x)['pos']\n",
    "\n",
    "df['full_text_score'] = None\n",
    "df['full_text_score_neg'] = None\n",
    "df['full_text_score_neu'] = None\n",
    "df['full_text_score_pos'] = None\n",
    "df['full_text_score'] = df['full_text'].map(score_full_text)\n",
    "df['full_text_score_neg'] = df['full_text'].map(score_neg_full_text)\n",
    "df['full_text_score_neu'] = df['full_text'].map(score_neu_full_text)\n",
    "df['full_text_score_pos'] = df['full_text'].map(score_pos_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating rows that contains differents created_at and influence_end_at column values\n",
    "\n",
    "new_rows = df[df['created_at'] != df['influence_end_at']]\n",
    "new_rows['created_at'] = new_rows['influence_end_at']\n",
    "new_rows['id'] = None\n",
    "\n",
    "new_df = df.append(new_rows)\n",
    "\n",
    "mask = df['created_at'].duplicated(keep=False)\n",
    "duplicados = df[mask]\n",
    "\n",
    "f_df = df[~mask].copy()\n",
    "f_df['Date'] = f_df['created_at']\n",
    "f_df['Score'] = f_df['full_text_score']\n",
    "f_df['PositiveScore'] = f_df['full_text_score_pos']\n",
    "f_df['NeutralScore'] = f_df['full_text_score_neu']\n",
    "f_df['NegativeScore'] = f_df['full_text_score_neg']\n",
    "f_df = f_df[['Date', 'Score', 'PositiveScore', 'NeutralScore', 'NegativeScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary with the tweet influence_end_at as key and the sum of the scores of sentimental analisys of tweets of that date and the number of tweets in that day as the value\n",
    "\n",
    "m = {}\n",
    "for d in duplicados['created_at'].unique():\n",
    "    if d not in m.keys():\n",
    "        m[d] = { \n",
    "            'count': 0, \n",
    "            'full_text_score': 0.0, \n",
    "            'full_text_score_pos': 0.0, \n",
    "            'full_text_score_neu': 0.0, \n",
    "            'full_text_score_neg': 0.0  \n",
    "            }\n",
    "    for i, row in df.loc[df['created_at'] == d].iterrows():\n",
    "        m[d]['full_text_score'] += row['full_text_score']\n",
    "        m[d]['full_text_score_pos'] += row['full_text_score_pos']\n",
    "        m[d]['full_text_score_neu'] += row['full_text_score_neu']\n",
    "        m[d]['full_text_score_neg'] += row['full_text_score_neg']\n",
    "        m[d]['count'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv file with columns Date and Score (Arithmetic mean of the twwets sentimental analisys score of that date )\n",
    "\n",
    "f_df2 = pd.DataFrame([ {\n",
    "    'Date': k, \n",
    "    'Score': v['full_text_score'] / v['count'], \n",
    "    'PositiveScore': v['full_text_score_pos'] / v['count'] , \n",
    "    'NeutralScore': v['full_text_score_neu'] / v['count'] , \n",
    "    'NegativeScore': v['full_text_score_neg'] / v['count'] \n",
    "    } for k, v in m.items()])\n",
    "\n",
    "df = pd.concat([f_df, f_df2], ignore_index=True)\n",
    "df.set_index('Date', inplace=True, drop=True)\n",
    "df = df[df['Score'] !=0]\n",
    "df['Score'] = df['Score'].round(decimals=4)\n",
    "df['PositiveScore'] = df['PositiveScore'].round(decimals=4)\n",
    "df['NeutralScore'] = df['NeutralScore'].round(decimals=4)\n",
    "df['NegativeScore'] = df['NegativeScore'].round(decimals=4)\n",
    "df.to_csv(\"btc_em_sentimental_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            Score  PositiveScore  NeutralScore  NegativeScore\n",
       "Date                                                                         \n",
       "2021-06-13 00:00:00+00:00  0.8689          0.226         0.774          0.000\n",
       "2021-06-04 00:00:00+00:00 -0.4215          0.000         0.517          0.483\n",
       "2021-05-22 00:00:00+00:00  0.4404          0.304         0.552          0.144\n",
       "2021-05-11 00:00:00+00:00  0.4404          0.438         0.562          0.000\n",
       "2021-05-07 00:00:00+00:00  0.5859          0.444         0.556          0.000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n      <th>PositiveScore</th>\n      <th>NeutralScore</th>\n      <th>NegativeScore</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-06-13 00:00:00+00:00</th>\n      <td>0.8689</td>\n      <td>0.226</td>\n      <td>0.774</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2021-06-04 00:00:00+00:00</th>\n      <td>-0.4215</td>\n      <td>0.000</td>\n      <td>0.517</td>\n      <td>0.483</td>\n    </tr>\n    <tr>\n      <th>2021-05-22 00:00:00+00:00</th>\n      <td>0.4404</td>\n      <td>0.304</td>\n      <td>0.552</td>\n      <td>0.144</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 00:00:00+00:00</th>\n      <td>0.4404</td>\n      <td>0.438</td>\n      <td>0.562</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2021-05-07 00:00:00+00:00</th>\n      <td>0.5859</td>\n      <td>0.444</td>\n      <td>0.556</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}