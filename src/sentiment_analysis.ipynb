{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd077642b1de94b3ecd25ac7cee94ae6d4cd14a15f998248e7a28e862a045f813e3",
   "display_name": "Python 3.6.9 64-bit ('tcc_puc': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "77642b1de94b3ecd25ac7cee94ae6d4cd14a15f998248e7a28e862a045f813e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Step 1 - Creating pandas dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "\n",
    "base_path_to_csv = os.path.join(os.getcwd() + '/eltweets/*.csv')\n",
    "csv_list = glob.glob(base_path_to_csv)\n",
    "\n",
    "# index_col removes the duplicates\n",
    "df_list = [pd.read_csv(csv, index_col='id') for csv in csv_list]\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "source": [
    "## Step 2 - Data cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 32 entries, 1404132183254523905 to 1328458535340949505\nData columns (total 5 columns):\n #   Column            Non-Null Count  Dtype              \n---  ------            --------------  -----              \n 0   created_at        32 non-null     datetime64[ns, UTC]\n 1   full_text         32 non-null     object             \n 2   retweet_count     32 non-null     int64              \n 3   influence_end_at  32 non-null     datetime64[ns, UTC]\n 4   retweet_count_n   32 non-null     float64            \ndtypes: datetime64[ns, UTC](2), float64(1), int64(1), object(1)\nmemory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index().drop_duplicates(subset='id', keep='first').set_index('id')\n",
    "\n",
    "df['full_text'] = df['full_text'].astype('unicode')\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: ', ' ', x)\n",
    "remove_users_ref = lambda x: re.sub(\"@[A-Za-z0-9]+\",\"\",x)\n",
    "remove_links = lambda x: re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", x)\n",
    "remove_hashtags_underlines = lambda x: x.replace(\"#\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "df['full_text'] = df['full_text'].map(remove_rt)\n",
    "df['full_text'] = df['full_text'].map(remove_users_ref)\n",
    "df['full_text'] = df['full_text'].map(remove_links)\n",
    "df['full_text'] = df['full_text'].map(remove_hashtags_underlines)\n",
    "\n",
    "df['full_text'] = df['full_text'].str.lower()\n",
    "df = df[(\n",
    "    df['full_text'].str.contains(\"bitcoin\") | \n",
    "    df['full_text'].str.contains(\"btc\") | \n",
    "    (df['full_text'].str.contains(\"crypto\") & ~df['full_text'].str.contains(\"doge\")))]\n",
    "df['full_text'] = df['full_text'].str.replace('&amp;', 'and')\n",
    "df['full_text'] = df['full_text'].str.replace('&', 'and')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸ’”', 'broke my heart')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸ¤£', 'laughing ')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸŽ¶', '')\n",
    "df['full_text'] = df['full_text'].str.replace(\"itâ€™s\", 'it is')\n",
    "df['full_text'] = df['full_text'].str.replace(\"donâ€™t\", 'do not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"canâ€™t\", 'can not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"wonâ€™t\", 'will not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"peopleâ€™s\", 'people')\n",
    "df['full_text'] = df['full_text'].str.replace(\"peopleâ€™s\", 'people')\n",
    "df['full_text'] = df['full_text'].str.replace(\"thereâ€™s\", 'there is')\n",
    " \n",
    "remove_pontuacao = lambda x:  re.sub(r'[^\\w\\s]', '', x)\n",
    "df['full_text'] = df['full_text'].map(remove_pontuacao)\n",
    "\n",
    "df['full_text'] = df['full_text'].str.replace(r'\\\\n',' ', regex=True) \n",
    "\n",
    "remove_multiplos_espacos = lambda x:  re.sub(' +', ' ', x)\n",
    "df['full_text'] = df['full_text'].map(remove_multiplos_espacos)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['created_at'] = df['created_at'].dt.normalize()\n",
    "df['influence_end_at'] = df['created_at']  + pd.DateOffset(days=1)\n",
    "df['influence_end_at'] = df['influence_end_at'].dt.normalize()\n",
    "\n",
    "df['full_text'] = df['full_text'].astype('unicode')\n",
    "df['retweet_count_n'] = None\n",
    "df['retweet_count_n'] = minmax_scale(df['retweet_count'])\n",
    "\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/prbpedro/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "score_full_text = lambda x: analyzer.polarity_scores(x)['compound']\n",
    "\n",
    "df['full_text_score'] = None\n",
    "df['full_text_score'] = df['full_text'].map(score_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}