{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('tcc_puc': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "77642b1de94b3ecd25ac7cee94ae6d4cd14a15f998248e7a28e862a045f813e3"
   }
  },
  "interpreter": {
   "hash": "77642b1de94b3ecd25ac7cee94ae6d4cd14a15f998248e7a28e862a045f813e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Step 1 - Creating pandas dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9737 entries, 1406073484300591105 to 1272993752890486784\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   created_at     9737 non-null   object\n",
      " 1   full_text      9737 non-null   object\n",
      " 2   retweet_count  9737 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 304.3+ KB\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/prbpedro/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "base_path_to_csv = os.path.join(os.getcwd() + '/eltweets/*.csv')\n",
    "csv_list = glob.glob(base_path_to_csv)\n",
    "\n",
    "# index_col removes the duplicates\n",
    "df_list = [pd.read_csv(csv, index_col='id') for csv in csv_list]\n",
    "df = pd.concat(df_list)\n",
    "df.info()"
   ]
  },
  {
   "source": [
    "## Step 2 - Data cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 73 entries, 1404132183254523905 to 1284290215561986048\nData columns (total 4 columns):\n #   Column            Non-Null Count  Dtype              \n---  ------            --------------  -----              \n 0   created_at        73 non-null     datetime64[ns, UTC]\n 1   full_text         73 non-null     object             \n 2   retweet_count     73 non-null     int64              \n 3   influence_end_at  73 non-null     datetime64[ns, UTC]\ndtypes: datetime64[ns, UTC](2), int64(1), object(1)\nmemory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index().drop_duplicates(subset='id', keep='first').set_index('id')\n",
    "\n",
    "df['full_text'] = df['full_text'].astype('unicode')\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: ', ' ', x)\n",
    "remove_users_ref = lambda x: re.sub(\"@[A-Za-z0-9]+\",\"\",x)\n",
    "remove_links = lambda x: re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", x)\n",
    "remove_hashtags_underlines = lambda x: x.replace(\"#\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "df['full_text'] = df['full_text'].map(remove_rt).map(remove_users_ref)\n",
    "df['full_text'] = df['full_text'].map(remove_links)\n",
    "df['full_text'] = df['full_text'].map(remove_hashtags_underlines)\n",
    "\n",
    "df['full_text'] = df['full_text'].str.lower()\n",
    "df = df[(\n",
    "    df['full_text'].str.contains(\"bitcoin\") | \n",
    "    df['full_text'].str.contains(\"btc\") | \n",
    "    df['full_text'].str.contains(\"crypto\") | \n",
    "    df['full_text'].str.contains(\"doge\"))]\n",
    "df['full_text'] = df['full_text'].str.replace('&amp;', 'and')\n",
    "df['full_text'] = df['full_text'].str.replace('&', 'and')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸ’”', 'broke my heart')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸ¤£', 'laughing ')\n",
    "df['full_text'] = df['full_text'].str.replace('ðŸŽ¶', '')\n",
    "df['full_text'] = df['full_text'].str.replace(\"itâ€™s\", 'it is')\n",
    "df['full_text'] = df['full_text'].str.replace(\"donâ€™t\", 'do not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"canâ€™t\", 'can not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"wonâ€™t\", 'will not')\n",
    "df['full_text'] = df['full_text'].str.replace(\"peopleâ€™s\", 'people')\n",
    "df['full_text'] = df['full_text'].str.replace(\"peopleâ€™s\", 'people')\n",
    "df['full_text'] = df['full_text'].str.replace(\"thereâ€™s\", 'there is')\n",
    " \n",
    "remove_pontuacao = lambda x:  re.sub(r'[^\\w\\s]', '', x)\n",
    "df['full_text'] = df['full_text'].map(remove_pontuacao)\n",
    "\n",
    "df['full_text'] = df['full_text'].str.replace(r'\\\\n',' ', regex=True) \n",
    "\n",
    "remove_multiplos_espacos = lambda x:  re.sub(' +', ' ', x)\n",
    "df['full_text'] = df['full_text'].map(remove_multiplos_espacos)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['created_at'] = df['created_at'].dt.normalize()\n",
    "df['influence_end_at'] = df['created_at']  + pd.DateOffset(days=1)\n",
    "df['influence_end_at'] = df['influence_end_at'].dt.normalize()\n",
    "\n",
    "df['full_text'] = df['full_text'].astype('unicode')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "score_full_text = lambda x: analyzer.polarity_scores(x)['compound']\n",
    "\n",
    "df['full_text_score'] = None\n",
    "df['full_text_score'] = df['full_text'].map(score_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = df[df['created_at'] != df['influence_end_at']]\n",
    "new_rows['created_at'] = new_rows['influence_end_at']\n",
    "new_rows['id'] = None\n",
    "\n",
    "new_df = df.append(new_rows)\n",
    "\n",
    "mask = df['created_at'].duplicated(keep=False)\n",
    "duplicados = df[mask]\n",
    "\n",
    "f_df = df[~mask].copy()\n",
    "f_df['Date'] = f_df['created_at']\n",
    "f_df['Score'] = f_df['full_text_score']\n",
    "f_df = f_df[['Date', 'Score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{Timestamp('2020-12-20 00:00:00+0000', tz='UTC'): {'count': 3,\n                                                   'full_text_score': 0.4404},\n Timestamp('2021-02-04 00:00:00+0000', tz='UTC'): {'count': 3,\n                                                   'full_text_score': -0.6369},\n Timestamp('2021-02-07 00:00:00+0000', tz='UTC'): {'count': 2,\n                                                   'full_text_score': 0.5563},\n Timestamp('2021-02-10 00:00:00+0000', tz='UTC'): {'count': 2,\n                                                   'full_text_score': -0.34},\n Timestamp('2021-02-11 00:00:00+0000', tz='UTC'): {'count': 2,\n                                                   'full_text_score': -0.8155},\n Timestamp('2021-02-14 00:00:00+0000', tz='UTC'): {'count': 2,\n                                                   'full_text_score': 0.7201},\n Timestamp('2021-02-19 00:00:00+0000', tz='UTC'): {'count': 3,\n                                                   'full_text_score': 0.18109999999999998},\n Timestamp('2021-02-20 00:00:00+0000', tz='UTC'): {'count': 5,\n                                                   'full_text_score': 1.2612},\n Timestamp('2021-03-02 00:00:00+0000', tz='UTC'): {'count': 3,\n                                                   'full_text_score': -0.5106},\n Timestamp('2021-03-13 00:00:00+0000', tz='UTC'): {'count': 3,\n                                                   'full_text_score': -0.3612},\n Timestamp('2021-03-24 00:00:00+0000', tz='UTC'): {'count': 3,\n                                                   'full_text_score': -0.0769},\n Timestamp('2021-04-15 00:00:00+0000', tz='UTC'): {'count': 2,\n                                                   'full_text_score': 0.0},\n Timestamp('2021-05-13 00:00:00+0000', tz='UTC'): {'count': 2,\n                                                   'full_text_score': 0.7724},\n Timestamp('2021-05-16 00:00:00+0000', tz='UTC'): {'count': 6,\n                                                   'full_text_score': -0.7955000000000001},\n Timestamp('2021-05-20 00:00:00+0000', tz='UTC'): {'count': 5,\n                                                   'full_text_score': 2.122},\n Timestamp('2021-05-24 00:00:00+0000', tz='UTC'): {'count': 3,\n                                                   'full_text_score': 2.2635},\n Timestamp('2021-05-25 00:00:00+0000', tz='UTC'): {'count': 2,\n                                                   'full_text_score': -0.1082}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "m = {}\n",
    "for d in duplicados['created_at'].unique():\n",
    "    if d not in m.keys():\n",
    "        m[d] = { 'count': 0, 'full_text_score': 0.0 }\n",
    "    for i, row in df.loc[df['created_at'] == d].iterrows():\n",
    "        m[d]['full_text_score'] += row['full_text_score']\n",
    "        m[d]['count'] += 1\n",
    "\n",
    "\n",
    "pprint(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df2 = pd.DataFrame([ {'Date': k, 'Score': v['full_text_score'] / v['count'] } for k, v in m.items()])\n",
    "\n",
    "df = pd.concat([f_df, f_df2], ignore_index=True)\n",
    "df.set_index('Date', inplace=True, drop=True)\n",
    "df = df[df['Score'] !=0]\n",
    "df.to_csv(\"btc_em_sentimental_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df = pd.read_csv(\"Bitcoin Historical Data - Investing.com.csv\", usecols = ['Date','Price'])\n",
    "btc_df['Date'] = pd.to_datetime(btc_df['Date'])\n",
    "btc_df['Date'] = btc_df['Date'].dt.normalize()\n",
    "btc_df = btc_df.reset_index().set_index('Date')\n",
    "btc_df = btc_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.index.tz_localize(None)\n",
    "btc_df.index = btc_df.index.tz_localize(None)\n",
    "merged = pd.merge(df, btc_df, on = ['Date'], how = 'outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['Score'] = merged['Score'].fillna(0)\n",
    "merged['Score'] = pd.to_numeric(merged['Score'])\n",
    "merged['Price'] = merged['Price'].str.replace(',', '')\n",
    "merged['Price'] = pd.to_numeric(merged['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('btc_value_em_tweets_sentimental_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}